{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Pantip (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>BANPU</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>53688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>BANPU</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>96710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>BANPU</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>77510900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker  Open  High   Low  Close    Volume\n",
       "Date                                                \n",
       "2018-02-14  BANPU  21.2  21.3  20.8   20.8  53688000\n",
       "2018-02-15  BANPU  20.9  21.8  20.9   21.8  96710000\n",
       "2018-02-16  BANPU  21.9  22.0  21.5   21.7  77510900"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1254"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>SCB</td>\n",
       "      <td>หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>BBL</td>\n",
       "      <td>หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>KBANK</td>\n",
       "      <td>หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker                                               Text\n",
       "2014-01-01    SCB  หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั...\n",
       "2014-01-01    BBL  หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั...\n",
       "2014-01-01  KBANK  หุ้น ธนาคาร ซื้อ ลงทุน พรุ่งนี้ ตัว ไหน ดี ครั..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>SCB</td>\n",
       "      <td>วัน พฤหัสบดี ที่ ๘ เดือน กุมภาพันธ์ พุทธ ศักรา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>PTT</td>\n",
       "      <td>มา วิเคราะห์ กัน ดีกว่า จะ แตก พา ร์ ไหม และ ก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>KBANK</td>\n",
       "      <td>ทำไม วันนี้ หุ้น น แบงค์ ตัว อื่น ขึ้น แต่ ทำไ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker                                               Text\n",
       "2018-02-08    SCB  วัน พฤหัสบดี ที่ ๘ เดือน กุมภาพันธ์ พุทธ ศักรา...\n",
       "2018-02-08    PTT  มา วิเคราะห์ กัน ดีกว่า จะ แตก พา ร์ ไหม และ ก...\n",
       "2018-02-08  KBANK  ทำไม วันนี้ หุ้น น แบงค์ ตัว อื่น ขึ้น แต่ ทำไ..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Total:', 9873)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from talib.abstract import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from pythainlp.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# target_stocks = ['BANPU','IRPC','PTT','BBL','KBANK','SCB','AOT','THAI','CPF','MINT',\n",
    "#                  'TU','SCC','CPN','CK','CPALL','HMPRO','BDMS','BH','ADVANC','JAS','TRUE']\n",
    "\n",
    "target_stocks = ['BANPU']\n",
    "\n",
    "df_price = pd.read_csv('merged_2013_2018.csv')\n",
    "df_price['Date'] = pd.to_datetime(df_price['Date'], format='%Y-%m-%d')\n",
    "df_price = df_price.loc[df_price['Ticker'].isin(target_stocks)]\n",
    "df_price['Date'] = df_price['Date'].dt.date\n",
    "df_price = df_price.set_index('Date')\n",
    "df_price.tail(3)\n",
    "len(df_price)\n",
    "\n",
    "df_pantip = pd.read_csv('data/pantip_all.csv')\n",
    "df_pantip['Date'] = pd.to_datetime(df_pantip['Date'], format='%Y-%m-%d')\n",
    "df_pantip = df_pantip.set_index('Date')\n",
    "df_pantip = df_pantip.sort_index()\n",
    "df_pantip = df_pantip['2014-1-1':'2018-2-8']\n",
    "df_pantip.index = df_pantip.index.date\n",
    "df_pantip.head(3)\n",
    "df_pantip.tail(3)\n",
    "\n",
    "'Total:', len(df_pantip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag & Horizon Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66d896305c74961b0c9d4e3fb5b9635"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431e8c913e424b6189460fec857cb8db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU :\t 172 43\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(172, 43)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Close(t+1)</th>\n",
       "      <th>Open(t)</th>\n",
       "      <th>High(t)</th>\n",
       "      <th>Low(t)</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Open(t-1)</th>\n",
       "      <th>High(t-1)</th>\n",
       "      <th>Low(t-1)</th>\n",
       "      <th>Close(t-1)</th>\n",
       "      <th>Open(t-2)</th>\n",
       "      <th>High(t-2)</th>\n",
       "      <th>Low(t-2)</th>\n",
       "      <th>Close(t-2)</th>\n",
       "      <th>Open(t-3)</th>\n",
       "      <th>High(t-3)</th>\n",
       "      <th>Low(t-3)</th>\n",
       "      <th>Close(t-3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>BANPU</td>\n",
       "      <td>ดอย เกิด ไร ขึ้น คะ ดอย บ้าน ปู ที่ ลง ทุกวัน ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>24.8</td>\n",
       "      <td>25.25</td>\n",
       "      <td>27.5</td>\n",
       "      <td>28.25</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker                                               Text  \\\n",
       "Date                                                                   \n",
       "2014-01-06  BANPU  ดอย เกิด ไร ขึ้น คะ ดอย บ้าน ปู ที่ ลง ทุกวัน ...   \n",
       "\n",
       "            Close(t+1)  Open(t)  High(t)  Low(t)  Close(t)  Open(t-1)  \\\n",
       "Date                                                                    \n",
       "2014-01-06        26.0     26.0    26.25    24.8     25.25       27.5   \n",
       "\n",
       "            High(t-1)  Low(t-1)  Close(t-1)  Open(t-2)  High(t-2)  Low(t-2)  \\\n",
       "Date                                                                          \n",
       "2014-01-06      28.25      26.5        26.5       30.0      30.25      28.0   \n",
       "\n",
       "            Close(t-2)  Open(t-3)  High(t-3)  Low(t-3)  Close(t-3)  \n",
       "Date                                                                \n",
       "2014-01-06        28.0       30.0      30.25      29.0       30.25  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Close(t+1)</th>\n",
       "      <th>Open(t)</th>\n",
       "      <th>High(t)</th>\n",
       "      <th>Low(t)</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Open(t-1)</th>\n",
       "      <th>High(t-1)</th>\n",
       "      <th>Low(t-1)</th>\n",
       "      <th>Close(t-1)</th>\n",
       "      <th>Open(t-2)</th>\n",
       "      <th>High(t-2)</th>\n",
       "      <th>Low(t-2)</th>\n",
       "      <th>Close(t-2)</th>\n",
       "      <th>Open(t-3)</th>\n",
       "      <th>High(t-3)</th>\n",
       "      <th>Low(t-3)</th>\n",
       "      <th>Close(t-3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-26</th>\n",
       "      <td>BANPU</td>\n",
       "      <td>ราคา เท่ากัน ตัว ไหน น่าสนใจ กว่า ช่วงนี้ กับ ...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker                                               Text  \\\n",
       "Date                                                                   \n",
       "2017-04-26  BANPU  ราคา เท่ากัน ตัว ไหน น่าสนใจ กว่า ช่วงนี้ กับ ...   \n",
       "\n",
       "            Close(t+1)  Open(t)  High(t)  Low(t)  Close(t)  Open(t-1)  \\\n",
       "Date                                                                    \n",
       "2017-04-26        19.5     19.5     19.7    19.0      19.3       20.6   \n",
       "\n",
       "            High(t-1)  Low(t-1)  Close(t-1)  Open(t-2)  High(t-2)  Low(t-2)  \\\n",
       "Date                                                                          \n",
       "2017-04-26       20.6      19.3        19.5       20.8       20.9      20.4   \n",
       "\n",
       "            Close(t-2)  Open(t-3)  High(t-3)  Low(t-3)  Close(t-3)  \n",
       "Date                                                                \n",
       "2017-04-26        20.6       20.6       20.8      20.5        20.7  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_lags = 3\n",
    "N_horizon = 1\n",
    "\n",
    "df_train = []\n",
    "df_test = []\n",
    "for stock in tqdm_notebook(target_stocks):\n",
    "    news_stocks = []\n",
    "    df_stock = df_pantip.loc[df_pantip['Ticker'] == stock]\n",
    "    prev_date = None\n",
    "    prev_text = None\n",
    "    \n",
    "    pbar = tqdm_notebook(total=len(df_stock))\n",
    "    for date, row in df_stock.iterrows():\n",
    "        if prev_date == None:\n",
    "            prev_date = date\n",
    "            prev_text = row['Text']\n",
    "        elif prev_date != date:\n",
    "            # horizon\n",
    "            tmp_date = copy.deepcopy(prev_date)\n",
    "            tmp_date += timedelta(days=1)\n",
    "            prices = []\n",
    "            count_lags = 0 \n",
    "            while count_lags < N_horizon:\n",
    "                price = df_price.loc[(df_price.index == tmp_date) & (df_price['Ticker'] == stock)].values\n",
    "                tmp_date += timedelta(days=1)\n",
    "                if len(price) == 0: continue\n",
    "                prices.append(price[0][4]) # Close price next day(s)\n",
    "                count_lags+=1\n",
    "            \n",
    "            # lag\n",
    "            tmp_date = copy.deepcopy(prev_date)\n",
    "            count_lags = 0 \n",
    "            while count_lags <= N_lags:\n",
    "                price = df_price.loc[(df_price.index == tmp_date) & (df_price['Ticker'] == stock)].values\n",
    "                tmp_date -= timedelta(days=1)\n",
    "                if len(price) == 0: continue\n",
    "                for val in price[0][:-1]: \n",
    "                    if type(val) != str: prices.append(val)\n",
    "                count_lags+=1\n",
    "\n",
    "            news_stocks.append([prev_date, stock, prev_text] + prices)\n",
    "            \n",
    "            prev_date = date\n",
    "            prev_text = row['Text']\n",
    "        elif prev_date == date:\n",
    "            prev_text += ' '+row['Text']\n",
    "        \n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    news_stocks = pd.DataFrame.from_records(news_stocks)\n",
    "    news_stocks.columns = ['Date', 'Ticker', 'Text', \n",
    "                           'Close(t+1)', # 'Close(t+2)','Close(t+3)','Close(t+4)','Close(t+5)',\n",
    "                           'Open(t)', 'High(t)', 'Low(t)', 'Close(t)',\n",
    "                           'Open(t-1)', 'High(t-1)', 'Low(t-1)', 'Close(t-1)',\n",
    "                           'Open(t-2)', 'High(t-2)', 'Low(t-2)', 'Close(t-2)',\n",
    "                           'Open(t-3)', 'High(t-3)', 'Low(t-3)', 'Close(t-3)',\n",
    "#                            'Open(t-4)', 'High(t-4)', 'Low(t-4)', 'Close(t-4)',\n",
    "#                            'Open(t-5)', 'High(t-5)', 'Low(t-5)', 'Close(t-5)'\n",
    "                          ]\n",
    "    news_stocks = news_stocks.set_index('Date')\n",
    "    \n",
    "    train_size = int(len(news_stocks) * 0.80)\n",
    "    test_size = len(news_stocks) - train_size\n",
    "    train, test = news_stocks.iloc[:train_size], news_stocks.iloc[train_size:]\n",
    "    print(stock, ':\\t',len(train), len(test))    \n",
    "    df_train.append(train)\n",
    "    df_test.append(test)\n",
    "    \n",
    "\n",
    "df_train = pd.concat(df_train, axis=0)\n",
    "df_test = pd.concat(df_test, axis=0)\n",
    "\n",
    "len(df_train), len(df_test) \n",
    "df_train.head(1)\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('data/pantip_train_(t-3).csv', index=False)\n",
    "# df_test.to_csv('data/pantip_test_(t-3).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vetorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 43)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close(t+1)</th>\n",
       "      <th>Open(t)</th>\n",
       "      <th>High(t)</th>\n",
       "      <th>Low(t)</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Open(t-1)</th>\n",
       "      <th>High(t-1)</th>\n",
       "      <th>Low(t-1)</th>\n",
       "      <th>Close(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>24.8</td>\n",
       "      <td>25.25</td>\n",
       "      <td>27.5</td>\n",
       "      <td>28.25</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>24.8</td>\n",
       "      <td>25.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ticker  Close(t+1)  Open(t)  High(t)  Low(t)  Close(t)  Open(t-1)  \\\n",
       "Date                                                                            \n",
       "2014-01-06       0        26.0     26.0    26.25    24.8     25.25       27.5   \n",
       "2014-01-07       0        26.5     25.0    26.50    25.0     26.00       26.0   \n",
       "\n",
       "            High(t-1)  Low(t-1)  Close(t-1) ...   490  491  492       493  \\\n",
       "Date                                        ...                             \n",
       "2014-01-06      28.25      26.5       26.50 ...   0.0  0.0  0.0  0.099438   \n",
       "2014-01-07      26.25      24.8       25.25 ...   0.0  0.0  0.0  0.000000   \n",
       "\n",
       "            494  495       496  497  498  499  \n",
       "Date                                           \n",
       "2014-01-06  0.0  0.0  0.062293  0.0  0.0  0.0  \n",
       "2014-01-07  0.0  0.0  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 518 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Close(t+1)</th>\n",
       "      <th>Open(t)</th>\n",
       "      <th>High(t)</th>\n",
       "      <th>Low(t)</th>\n",
       "      <th>Close(t)</th>\n",
       "      <th>Open(t-1)</th>\n",
       "      <th>High(t-1)</th>\n",
       "      <th>Low(t-1)</th>\n",
       "      <th>Close(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-26</th>\n",
       "      <td>0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ticker  Close(t+1)  Open(t)  High(t)  Low(t)  Close(t)  Open(t-1)  \\\n",
       "Date                                                                            \n",
       "2017-04-26       0        19.5     19.5     19.7    19.0      19.3       20.6   \n",
       "2017-05-10       0        17.9     19.2     19.3    18.4      18.5       19.2   \n",
       "\n",
       "            High(t-1)  Low(t-1)  Close(t-1) ...   490  491  492       493  \\\n",
       "Date                                        ...                             \n",
       "2017-04-26       20.6      19.3        19.5 ...   0.0  0.0  0.0  0.075259   \n",
       "2017-05-10       19.4      19.1        19.2 ...   0.0  0.0  0.0  0.135617   \n",
       "\n",
       "            494       495  496  497  498  499  \n",
       "Date                                           \n",
       "2017-04-26  0.0  0.000000  0.0  0.0  0.0  0.0  \n",
       "2017-05-10  0.0  0.038058  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 518 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['BANPU'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('thai')\n",
    "stop_words.remove('ขึ้น')\n",
    "stop_words.remove('ลง')\n",
    "\n",
    "vertorizer = TfidfVectorizer(stop_words=stop_words, \n",
    "                             max_df=0.9, \n",
    "                             min_df=2, \n",
    "                             max_features=500)\n",
    "\n",
    "tfidf_train = vertorizer.fit_transform(df_train['Text'])\n",
    "tfidf_test = vertorizer.transform(df_test['Text'])\n",
    "\n",
    "df_tfidf_train = pd.DataFrame.from_records(tfidf_train.toarray())\n",
    "df_tfidf_test = pd.DataFrame.from_records(tfidf_test.toarray())\n",
    "\n",
    "df_tfidf_train = df_tfidf_train.set_index(df_train.index)\n",
    "df_tfidf_test = df_tfidf_test.set_index(df_test.index)\n",
    "\n",
    "len(df_tfidf_train), len(df_tfidf_test)\n",
    "\n",
    "# replace Text with TF-IDF vector\n",
    "x_train = df_train.drop(['Text'], axis=1)\n",
    "x_train = pd.concat([x_train, df_tfidf_train], axis=1)\n",
    "\n",
    "x_test = df_test.drop(['Text'], axis=1)\n",
    "x_test = pd.concat([x_test, df_tfidf_test], axis=1)\n",
    "\n",
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "x_train['Ticker'] = le.fit_transform(x_train['Ticker'])\n",
    "x_test['Ticker'] = le.transform(x_test['Ticker'])\n",
    "x_train.head(2)\n",
    "x_test.head(2)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172, 517), (172, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Horizon = 'Close(t+1)'\n",
    "y_train = x_train[[Horizon]]\n",
    "x_train = x_train.drop(['Close(t+1)'], axis=1).copy()\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Each Stcok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluator(clf, df_test, le, isXGB=False, isLSTM=False):\n",
    "    RMSEs, MAEs, MAPEs, DAs = [], [], [], []\n",
    "    results = []\n",
    "    for stock in target_stocks:\n",
    "        x_tmp = df_test.loc[df_test['Ticker'] == le.transform([stock])[0]].copy()\n",
    "        \n",
    "        y_tmp = x_tmp[Horizon].values\n",
    "        \n",
    "        # Directional Accuracy\n",
    "        changes = x_tmp[Horizon] -  x_tmp['Close(t)']\n",
    "        y_true_da = []\n",
    "        for change in changes:\n",
    "            y_true_da.append(1 if change >= 0 else 0)\n",
    "                \n",
    "        x_tmp = x_tmp.drop(['Close(t+1)'], axis=1)\n",
    "        \n",
    "        if isXGB:\n",
    "            y_pred = clf.predict(xgboost.DMatrix(x_tmp))\n",
    "        elif isLSTM:\n",
    "            x = x_tmp.values\n",
    "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "            y_pred = clf.predict(x)\n",
    "        else:\n",
    "            y_pred = clf.predict(x_tmp.as_matrix())\n",
    "        \n",
    "        # Directional Accuracy Pred\n",
    "        changes = np.reshape(y_pred, (-1,1)) -  np.reshape(x_tmp['Close(t)'],(-1,1))\n",
    "        y_pred_da = []\n",
    "        for change in changes:\n",
    "            y_pred_da.append(1 if change >= 0 else 0)\n",
    "        \n",
    "        RMSE = np.sqrt(mean_squared_error(y_tmp, y_pred))\n",
    "        MAE = mean_absolute_error(y_tmp, y_pred)\n",
    "        MAPE = mean_absolute_percentage_error(y_tmp, y_pred)\n",
    "        DA = accuracy_score(y_true_da, y_pred_da)\n",
    "        print(stock, \"\\tRMSE: %.2f\\t MAE: %.2f \\tMAPE: %.2f \\tDA: %.2f\" % (RMSE, MAE, MAPE, DA))\n",
    "        RMSEs.append(RMSE)\n",
    "        MAEs.append(MAE)\n",
    "        MAPEs.append(MAPE)\n",
    "        DAs.append(DA)\n",
    "    \n",
    "    print('\\nmean RMSE:', round(np.mean(RMSEs),2))\n",
    "    print('mean MAE:', round(np.mean(MAEs),2))\n",
    "    print('mean MAPE:', round(np.mean(MAPEs),2))\n",
    "    print('mean DA:', round(np.mean(DAs),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_evaluator(dt, rf, ada_dt, ada_rf, gb, xgb, df_test, le):\n",
    "    RMSEs, MAEs, MAPEs, DAs = [], [], [], []\n",
    "    results = []\n",
    "    for stock in target_stocks:\n",
    "        x_tmp = df_test.loc[df_test['Ticker'] == le.transform([stock])[0]].copy()\n",
    "        \n",
    "        y_tmp = x_tmp[Horizon].values\n",
    "        \n",
    "        # Directional Accuracy\n",
    "        changes = x_tmp[Horizon] -  x_tmp['Close(t)']\n",
    "        y_true_da = []\n",
    "        for change in changes:\n",
    "            y_true_da.append(1 if change >= 0 else 0)\n",
    "                \n",
    "        x_tmp = x_tmp.drop(['Close(t+1)'], axis=1)\n",
    "        \n",
    "        # Prediction\n",
    "        \n",
    "        y_dt = dt.predict(x_tmp.as_matrix())\n",
    "        y_rf = rf.predict(x_tmp.as_matrix())\n",
    "        y_ada_dt = ada_dt.predict(x_tmp.as_matrix())\n",
    "        y_ada_rf = ada_rf.predict(x_tmp.as_matrix())\n",
    "        y_gb = gb.predict(x_tmp.as_matrix())\n",
    "        \n",
    "        y_xgb = xgb.predict(xgboost.DMatrix(x_tmp))\n",
    "        \n",
    "#             x = x_tmp.values\n",
    "#             x = x.reshape((x.shape[0], 1, x.shape[1]))\n",
    "#             y_pred = clf.predict(x)\n",
    "        y_pred = (y_dt+y_rf+y_ada_dt+y_ada_rf+y_gb+y_xgb)/6\n",
    "\n",
    "        # Directional Accuracy Pred\n",
    "        changes = np.reshape(y_pred, (-1,1)) -  np.reshape(x_tmp['Close(t)'],(-1,1))\n",
    "        y_pred_da = []\n",
    "        for change in changes:\n",
    "            y_pred_da.append(1 if change >= 0 else 0)\n",
    "        \n",
    "        RMSE = np.sqrt(mean_squared_error(y_tmp, y_pred))\n",
    "        MAE = mean_absolute_error(y_tmp, y_pred)\n",
    "        MAPE = mean_absolute_percentage_error(y_tmp, y_pred)\n",
    "        DA = accuracy_score(y_true_da, y_pred_da)\n",
    "        print(stock, \"\\tRMSE: %.2f\\t MAE: %.2f \\tMAPE: %.2f \\tDA: %.2f\" % (RMSE, MAE, MAPE, DA))\n",
    "        RMSEs.append(RMSE)\n",
    "        MAEs.append(MAE)\n",
    "        MAPEs.append(MAPE)\n",
    "        DAs.append(DA)\n",
    "    \n",
    "    print('\\nmean RMSE:', round(np.mean(RMSEs),2))\n",
    "    print('mean MAE:', round(np.mean(MAEs),2))\n",
    "    print('mean MAPE:', round(np.mean(MAPEs),2))\n",
    "    print('mean DA:', round(np.mean(DAs),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.32\t MAE: 0.21 \tMAPE: 1.16 \tDA: 0.62\n",
      "\n",
      "mean RMSE: 0.32\n",
      "mean MAE: 0.21\n",
      "mean MAPE: 1.16\n",
      "mean DA: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_evaluator(decis_tree_regr, \n",
    "                   rnd_forest_regr, \n",
    "                   adaboost_dt_regr, \n",
    "                   adaboost_rf_regr, \n",
    "                   gbr, \n",
    "                   xgb,\n",
    "                   x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.79\t MAE: 0.61 \tMAPE: 12.97 \tDA: 0.53\n",
      "\n",
      "mean RMSE: 0.79\n",
      "mean MAE: 0.61\n",
      "mean MAPE: 12.97\n",
      "mean DA: 0.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lineregr = linear_model.LinearRegression()\n",
    "lineregr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(lineregr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.59\t MAE: 0.46 \tMAPE: 2.41 \tDA: 0.53\n",
      "\n",
      "mean RMSE: 0.59\n",
      "mean MAE: 0.46\n",
      "mean MAPE: 2.41\n",
      "mean DA: 0.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(svr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decistion Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 1.10\t MAE: 0.73 \tMAPE: 3.62 \tDA: 0.47\n",
      "\n",
      "mean RMSE: 1.1\n",
      "mean MAE: 0.73\n",
      "mean MAPE: 3.62\n",
      "mean DA: 0.4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "decis_tree_regr = tree.DecisionTreeRegressor()\n",
    "decis_tree_regr.fit(x_train, y_train)\n",
    "evaluator(decis_tree_regr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regrssor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.73\t MAE: 0.55 \tMAPE: 2.84 \tDA: 0.53\n",
      "\n",
      "mean RMSE: 0.73\n",
      "mean MAE: 0.55\n",
      "mean MAPE: 2.84\n",
      "mean DA: 0.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "rnd_forest_regr = ensemble.RandomForestRegressor(n_jobs=-1)\n",
    "rnd_forest_regr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(rnd_forest_regr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         learning_rate=1, loss='linear', n_estimators=50,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.78\t MAE: 0.52 \tMAPE: 2.63 \tDA: 0.58\n",
      "\n",
      "mean RMSE: 0.78\n",
      "mean MAE: 0.52\n",
      "mean MAPE: 2.63\n",
      "mean DA: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_dt_regr = ensemble.AdaBoostRegressor(base_estimator=tree.DecisionTreeRegressor(),\n",
    "                                           learning_rate=1, \n",
    "                                           n_estimators=50, \n",
    "                                           loss='linear')\n",
    "adaboost_dt_regr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(adaboost_dt_regr, x_test, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "         learning_rate=1, loss='linear', n_estimators=50,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.83\t MAE: 0.59 \tMAPE: 3.00 \tDA: 0.40\n",
      "\n",
      "mean RMSE: 0.83\n",
      "mean MAE: 0.59\n",
      "mean MAPE: 3.0\n",
      "mean DA: 0.3953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_rf_regr = ensemble.AdaBoostRegressor(base_estimator=ensemble.RandomForestRegressor(n_jobs=-1),\n",
    "                                           learning_rate=1, \n",
    "                                           n_estimators=50, \n",
    "                                           loss='linear')\n",
    "adaboost_rf_regr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(adaboost_rf_regr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.80\t MAE: 0.60 \tMAPE: 3.08 \tDA: 0.35\n",
      "\n",
      "mean RMSE: 0.8\n",
      "mean MAE: 0.6\n",
      "mean MAPE: 3.08\n",
      "mean DA: 0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr = ensemble.GradientBoostingRegressor(n_estimators=500, \n",
    "                                         learning_rate=0.1,\n",
    "                                         max_depth=4,\n",
    "                                         min_samples_split=2,\n",
    "                                         loss='ls',\n",
    "                                        )\n",
    "gbr.fit(x_train, y_train)\n",
    "\n",
    "evaluator(gbr, x_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 144)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15, random_state=10)\n",
    "len(x_train), len(x_valid)\n",
    "\n",
    "d_train = xgboost.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgboost.DMatrix(x_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:17.8789\tvalid-mae:18.6906\n",
      "Multiple eval metrics have been passed: 'valid-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mae hasn't improved in 50 rounds.\n",
      "[100]\ttrain-mae:13.048\tvalid-mae:13.7789\n",
      "[200]\ttrain-mae:6.7639\tvalid-mae:7.22708\n",
      "[300]\ttrain-mae:2.8495\tvalid-mae:3.07734\n",
      "[400]\ttrain-mae:1.11178\tvalid-mae:1.2272\n",
      "[500]\ttrain-mae:0.44533\tvalid-mae:0.564752\n",
      "[600]\ttrain-mae:0.218248\tvalid-mae:0.378043\n",
      "[700]\ttrain-mae:0.150215\tvalid-mae:0.347583\n",
      "[800]\ttrain-mae:0.120847\tvalid-mae:0.344008\n",
      "Stopping. Best iteration:\n",
      "[797]\ttrain-mae:0.121591\tvalid-mae:0.343887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'booster':'dart',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators':300,\n",
    "    'subsample': 0.9,\n",
    "    'objective': 'reg:tweedie',\n",
    "    'eval_metric': 'mae',\n",
    "    'reg_lambda': 0.8,\n",
    "    'reg_alpha': 0.2,\n",
    "    'silent': 1,\n",
    "}\n",
    "\n",
    "xgb = xgboost.train(params, d_train, \n",
    "                    num_boost_round=5000, \n",
    "                    evals=[(d_train, 'train'), (d_valid, 'valid')], \n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose_eval=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 0.38\t MAE: 0.24 \tMAPE: 1.29 \tDA: 0.57\n",
      "\n",
      "mean RMSE: 0.38\n",
      "mean MAE: 0.24\n",
      "mean MAPE: 1.29\n",
      "mean DA: 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator(xgb, x_test, le, isXGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgboost.plot_importance(xgb, height=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 517, 1) (816, 1)\n",
      "(144, 517, 1) (144, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X = x_train.values\n",
    "val_X = x_valid.values\n",
    "# test_X = x_test.values\n",
    "\n",
    "train_y = y_train.values\n",
    "val_y = y_valid.values\n",
    "# test_y = y_test.values\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "val_X = val_X.reshape(val_X.shape[0], val_X.shape[1], 1)\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(val_X.shape, val_y.shape)\n",
    "# print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(train_X.shape[1], 1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256, return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(256, return_sequences=True))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"model/LSTM.h5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             period=1\n",
    "                            )\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', \n",
    "                      min_delta=0, \n",
    "                      patience=100,\n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "\n",
    "# access via $ tensorboard --logdir=./logs\n",
    "tensorboard = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 816 samples, validate on 144 samples\n",
      "Epoch 1/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 12.2562Epoch 00000: val_loss improved from inf to 4.61384, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 170s - loss: 12.0979 - val_loss: 4.6138\n",
      "Epoch 2/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.3725Epoch 00001: val_loss improved from 4.61384 to 3.76735, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 172s - loss: 3.3742 - val_loss: 3.7673\n",
      "Epoch 3/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2220Epoch 00002: val_loss did not improve\n",
      "816/816 [==============================] - 170s - loss: 3.2265 - val_loss: 3.7692\n",
      "Epoch 4/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2185Epoch 00003: val_loss did not improve\n",
      "816/816 [==============================] - 167s - loss: 3.2233 - val_loss: 3.7746\n",
      "Epoch 5/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2176Epoch 00004: val_loss did not improve\n",
      "816/816 [==============================] - 164s - loss: 3.2222 - val_loss: 3.7686\n",
      "Epoch 6/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2179Epoch 00005: val_loss did not improve\n",
      "816/816 [==============================] - 163s - loss: 3.2226 - val_loss: 3.7674\n",
      "Epoch 7/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2184Epoch 00006: val_loss did not improve\n",
      "816/816 [==============================] - 167s - loss: 3.2230 - val_loss: 3.7677\n",
      "Epoch 8/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2185Epoch 00007: val_loss did not improve\n",
      "816/816 [==============================] - 166s - loss: 3.2231 - val_loss: 3.7675\n",
      "Epoch 9/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2186Epoch 00008: val_loss did not improve\n",
      "816/816 [==============================] - 165s - loss: 3.2232 - val_loss: 3.7674\n",
      "Epoch 10/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2186Epoch 00009: val_loss improved from 3.76735 to 3.76735, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 165s - loss: 3.2232 - val_loss: 3.7673\n",
      "Epoch 11/1000\n",
      "800/816 [============================>.] - ETA: 2s - loss: 3.2191Epoch 00010: val_loss did not improve\n",
      "816/816 [==============================] - 159s - loss: 3.2237 - val_loss: 3.7683\n",
      "Epoch 12/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2188Epoch 00011: val_loss improved from 3.76735 to 3.76730, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 170s - loss: 3.2234 - val_loss: 3.7673\n",
      "Epoch 13/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2193Epoch 00012: val_loss did not improve\n",
      "816/816 [==============================] - 169s - loss: 3.2239 - val_loss: 3.7681\n",
      "Epoch 14/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2189Epoch 00013: val_loss improved from 3.76730 to 3.76726, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 173s - loss: 3.2235 - val_loss: 3.7673\n",
      "Epoch 15/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2195Epoch 00014: val_loss did not improve\n",
      "816/816 [==============================] - 172s - loss: 3.2241 - val_loss: 3.7679\n",
      "Epoch 16/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2191Epoch 00015: val_loss did not improve\n",
      "816/816 [==============================] - 165s - loss: 3.2237 - val_loss: 3.7675\n",
      "Epoch 17/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2195Epoch 00016: val_loss did not improve\n",
      "816/816 [==============================] - 166s - loss: 3.2241 - val_loss: 3.7678\n",
      "Epoch 18/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2192Epoch 00017: val_loss did not improve\n",
      "816/816 [==============================] - 169s - loss: 3.2238 - val_loss: 3.7674\n",
      "Epoch 19/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2196Epoch 00018: val_loss did not improve\n",
      "816/816 [==============================] - 167s - loss: 3.2242 - val_loss: 3.7677\n",
      "Epoch 20/1000\n",
      "800/816 [============================>.] - ETA: 3s - loss: 3.2193Epoch 00019: val_loss did not improve\n",
      "816/816 [==============================] - 162s - loss: 3.2239 - val_loss: 3.7673\n",
      "Epoch 21/1000\n",
      "800/816 [============================>.] - ETA: 2s - loss: 3.2192Epoch 00020: val_loss improved from 3.76726 to 3.76724, saving model to model/LSTM.h5\n",
      "816/816 [==============================] - 158s - loss: 3.2238 - val_loss: 3.7672\n",
      "Epoch 22/1000\n",
      "288/816 [=========>....................] - ETA: 96s - loss: 3.4567 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-44997c8698e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m          )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_X, \n",
    "          y=train_y,\n",
    "          epochs=1000,\n",
    "          batch_size=32,\n",
    "          validation_data=(val_X, val_y),\n",
    "          verbose=1,\n",
    "          shuffle=False,\n",
    "          callbacks=[checkpoint, earlystopping, tensorboard]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 2.10\t MAE: 1.98 \tMAPE: 11.19 \tDA: 0.60\n",
      "\n",
      "mean RMSE: 2.1\n",
      "mean MAE: 1.98\n",
      "mean MAPE: 11.19\n",
      "mean DA: 0.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator(model, x_test, le, isLSTM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/layers/wrappers.py:257: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/layers/wrappers.py:257: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/layers/wrappers.py:257: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/layers/wrappers.py:257: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n",
      "/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py:135: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(2, train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected bidirectional_11_input to have shape (None, 2, 517) but got array with shape (816, 1, 517)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-43e0538cb466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m          )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1306\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected bidirectional_11_input to have shape (None, 2, 517) but got array with shape (816, 1, 517)"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_X, \n",
    "          y=train_y,\n",
    "          epochs=10000,\n",
    "          batch_size=1024,\n",
    "          validation_data=(val_X, val_y),\n",
    "          verbose=1,\n",
    "          shuffle=False,\n",
    "          callbacks=[checkpoint, earlystopping, tensorboard]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANPU \tRMSE: 2.11\t MAE: 1.99 \tMAPE: 11.29 \tDA: 0.60\n",
      "\n",
      "mean RMSE: 2.11\n",
      "mean MAE: 1.99\n",
      "mean MAPE: 11.29\n",
      "mean DA: 0.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:57: FutureWarning:\n",
      "\n",
      "reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator(model, x_test, le, isLSTM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "np.random.random((10, timesteps, data_dim)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 517)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(816, 517, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = x_train.values\n",
    "val_X = x_valid.values\n",
    "train_X.shape\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
